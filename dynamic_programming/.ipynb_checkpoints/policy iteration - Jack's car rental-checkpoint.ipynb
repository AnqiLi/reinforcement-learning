{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jack manages two locations for a nationwide car rental company.\n",
    "\n",
    "Each day, some number of customers arrive at each location to rent cars. If Jack has a car available, he\n",
    "rents it out and is credited $10 by the national company. If he is out of cars at that location, then the\n",
    "business is lost. Cars become available for renting the day after they are returned.\n",
    "\n",
    "To help ensure that cars are available where they are needed, Jack can move them between the two locations overnight, at a cost of $2 per car moved.\n",
    "\n",
    "We assume that the number of cars requested and returned at each location are Poisson random variables, meaning that the probability that the number is n is λn e−λ, where λ is the expected number.\n",
    "\n",
    "Suppose λ is 3 and 4 for rental requests at the first and second locations and 3 and 2 for returns. To simplify the problem slightly, we assume that there can be no more than 20 cars at each location (any additional cars are returned to the nationwide company, and thus disappear from the problem) and a maximum of five cars can be moved from one location to the other in one night.\n",
    "\n",
    "We take the discount rate to be γ = 0.9 and formulate this as a continuing finite MDP, where the time steps are days, the state is the number of cars at each location at the end of the day, and the actions are the net numbers of cars moved between the two locations overnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_dict = {}\n",
    "prob_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2, 2), 5, (10, 10)\n",
    "(2, 2), 5, (-3, 7)\n",
    "\n",
    "(2, 2), 5, (-2, -2) (max requested)  \n",
    "(2, 2), 5, (-5, 5)  \n",
    "(2, 2), 5, (+15, +5) (max returned)  \n",
    "\n",
    "\n",
    "10 + 2 - 2 + 5\n",
    "new_state + action\n",
    "new_state - action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability_reward: (0, 0) (0, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.015299657929279972, 0)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_reward((0, 0), 0, (0, 0), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_reward(state, action, new_state, verbose=False):\n",
    "    requested_1 = state[0]\n",
    "    requested_2 = state[1]\n",
    "    returned_1 = new_state[0] + action# - state[0] + requested_1\n",
    "    returned_2 = new_state[1] - action# - state[1] + requested_2\n",
    "    \n",
    "    if min(requested_1, requested_2, returned_1, returned_2) < 0: return (0, -1000)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"probability_reward:\", \"({}, {})\".format(requested_1, returned_1), \\\n",
    "              \"({}, {})\".format(requested_2, returned_2))\n",
    "    p_1, r_1 = prob(requested_1, returned_1, 3, 3)\n",
    "    p_2, r_2 = prob(requested_2, returned_2, 4, 2)\n",
    "    \n",
    "    p = p_1 * p_2\n",
    "    r = (r_1 + r_2) - abs(action)*2\n",
    "            \n",
    "    return p, r\n",
    "\n",
    "from math import factorial, e\n",
    "\n",
    "def poisson_distribution(n, lb):\n",
    "    key = (n, lb)\n",
    "    if key in poisson_dict: return poisson_dict[key]\n",
    "    value = (pow(lb, n)/factorial(n))*(pow(e, -lb))\n",
    "    poisson_dict[key] = value\n",
    "    return value\n",
    "\n",
    "def prob(requested, returned, lb_request, lb_return, verbose=False):\n",
    "    if verbose: print(\"prob:\", requested, returned, lb_request, lb_return)\n",
    "    key = (requested, returned, lb_request, lb_return)\n",
    "    if key in prob_dict: return prob_dict[key]\n",
    "    \n",
    "    min_n = min(requested, returned)\n",
    "    p = 0\n",
    "    r = 0\n",
    "    \n",
    "    for n in range(min_n+1):\n",
    "        p_requested = poisson_distribution(requested - min_n + n, lb_request)\n",
    "        p_returned = poisson_distribution(returned - min_n + n, lb_return)\n",
    "        p += p_requested * p_returned\n",
    "        r += ((requested - min_n + n)*10) # * (p_requested + p_returned)\n",
    "    \n",
    "    value = (p, r)\n",
    "    prob_dict[key] = value\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_rental_probability_cache = {}\n",
    "def loc_rental_probability(start, end, rent_lam, return_lam):\n",
    "    \"\"\"\n",
    "    calculate the rental probabilities and rewards given a particular start and end count\n",
    "    :param start: the day start count\n",
    "    :param end: the day end count\n",
    "    :param rent_lam: the rental poisson lambda\n",
    "    :param return_lam: the return poisson lambda\n",
    "    :return: a list of probability/reward tuples enumerating the possible outcomes.\n",
    "    \"\"\"\n",
    "    \n",
    "    key = (start, end, rent_lam, return_lam)\n",
    "    if key in loc_rental_probability_cache: return loc_rental_probability_cache[key]\n",
    "    \n",
    "    rv = []\n",
    "    for rented in range(0, start+1):\n",
    "        remaining = start - rented\n",
    "        returned = end - remaining\n",
    "        if returned >= 0: # feasible\n",
    "            if remaining == 0:\n",
    "                # cars that can be rented is capped at the number on the lot, but in theory an infinite number of customers could arrive...\n",
    "                prob = 1\n",
    "                for i in range(0, rented):\n",
    "                    prob -= poisson_distribution(i, rent_lam)\n",
    "            else:\n",
    "                prob = poisson_distribution(rented, rent_lam)\n",
    "            if end == 20:\n",
    "                # lot size is capped at 20, but in theory an infinite number of cars could be returned...\n",
    "                return_prob = 1\n",
    "                for i in range(0, returned):\n",
    "                    return_prob -= poisson_distribution(i, return_lam)\n",
    "            else:\n",
    "                return_prob = poisson_distribution(returned, return_lam)\n",
    "\n",
    "            prob *= return_prob\n",
    "            reward = 10 * rented\n",
    "            rv.append((prob, reward))\n",
    "\n",
    "    loc_rental_probability_cache[key] = rv\n",
    "    return rv\n",
    "\n",
    "rental_probabilities_cache = {}\n",
    "def rental_probabilities(start_state, action, end_state):\n",
    "    \"\"\"\n",
    "    calculate the day activity (rental/return activity) probabilities\n",
    "    :param start_state: the start of day state\n",
    "    :return: a next_state -> (transition probability, *expected* reward) tuples.\n",
    "    \"\"\"\n",
    "    rv = {}\n",
    "    \n",
    "    key = ((start_state[0], start_state[1]), action, (end_state[0], end_state[1]))\n",
    "    if key in rental_probabilities_cache: return rental_probabilities_cache[key]\n",
    "    \n",
    "    start_state = (min(20, start_state[0] - action), min(20, start_state[1] + action))\n",
    "\n",
    "    l1_probs = loc_rental_probability(start_state[0], end_state[0], 3, 3)\n",
    "    l2_probs = loc_rental_probability(start_state[1], end_state[1], 4, 2)\n",
    "    prob = 0\n",
    "    reward = 0\n",
    "    for l1p, l1r in l1_probs:\n",
    "        for l2p, l2r in l2_probs:\n",
    "            p = l1p*l2p\n",
    "            prob += p\n",
    "            reward += p * (l1r+l2r)\n",
    "    \n",
    "    rental_probabilities_cache[key] = (prob, reward)\n",
    "            \n",
    "    return (prob, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Rental(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.actions = np.asarray(range(-5, 6))\n",
    "        self.num_actions = len(self.actions)\n",
    "        self.states = np.asarray([[i,j] for i in range(21) for j in range(21)])\n",
    "        self.num_states = len(self.states)\n",
    "        \n",
    "        self.probabilities = np.full([self.num_states, self.num_actions, self.num_states], 0, dtype=np.float32)\n",
    "        self.rewards = np.full([self.num_states, self.num_actions, self.num_states], 0, dtype=np.float32)\n",
    "        self.costs = np.full([self.num_states, self.num_actions], 0, dtype=np.float32)\n",
    "        \n",
    "        for state_idx, state in enumerate(self.states):\n",
    "            for action_idx, action in enumerate(self.actions):\n",
    "                for new_state_idx, new_state in enumerate(self.states):\n",
    "                    \n",
    "                    p,r = rental_probabilities(state, action, new_state)\n",
    "                    self.probabilities[state_idx][action_idx][new_state_idx] = p\n",
    "                    self.rewards[state_idx][action_idx][new_state_idx] = r\n",
    "                    self.costs[state_idx][action_idx] = abs(action)*2\n",
    "                    \n",
    "        #self.probabilities[:,0] = 1\n",
    "        #self.probabilities[0,:] = 1\n",
    "\n",
    "r = Rental()\n",
    "r.states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_state = np.full(r.num_states, 0)\n",
    "z = np.zeros(r.num_actions)\n",
    "z[5] = 1\n",
    "policy = np.full([r.num_states, len(r.actions)], z).reshape(r.num_states, len(r.actions), 1)\n",
    "env = r\n",
    "\n",
    "#v = ((value_state*discount_factor + env.rewards)*env.probabilities*policy)\n",
    "#v = ((v*discount_factor + env.rewards)*env.probabilities*policy)\n",
    "#((v*discount_factor + env.rewards)*env.probabilities*policy).sum(axis=2).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "policy (0, 0): 0\n"
     ]
    }
   ],
   "source": [
    "value_state = np.full(r.num_states, 0)\n",
    "z = np.zeros(r.num_actions)\n",
    "z[5] = 1\n",
    "policy = np.full([r.num_states, len(r.actions)], z).reshape(r.num_states, len(r.actions), 1)\n",
    "\n",
    "def policy_eval(policy, value_state, env, discount_factor=1.0, theta=0.00001):\n",
    "    # while True:\n",
    "    for i in range(1000):\n",
    "        delta = 0\n",
    "        old_value_state = value_state\n",
    "        \n",
    "        # new_v_action_state = (value_state*discount_factor + env.rewards)*env.probabilities*policy\n",
    "        new_v_action_state = (env.rewards - env.costs.reshape(441, 11, 1) + (value_state*discount_factor)*env.probabilities)*policy\n",
    "        new_v = new_v_action_state.sum(axis=2).sum(axis=1)\n",
    "        value_state = new_v\n",
    "        \n",
    "        delta = max(delta, np.abs(old_value_state - value_state).max())\n",
    "        if delta < theta:\n",
    "            print(i)\n",
    "            break\n",
    "\n",
    "    return value_state\n",
    "\n",
    "discount_factor=0.9\n",
    "theta=0.0001\n",
    "\n",
    "def policy_iteration(policy, value_state, env):\n",
    "    value_state = policy_eval(policy, value_state, env, discount_factor=discount_factor, theta=theta)\n",
    "    \n",
    "    # new_policy = (env.probabilities * (env.rewards + discount_factor*value_state)).sum(axis=2).argmax(axis=1)\n",
    "    new_policy = (env.rewards - env.costs.reshape(441, 11, 1) + env.probabilities * (discount_factor*value_state)).sum(axis=2).argmax(axis=1)\n",
    "    new_policy = new_policy.reshape(new_policy.shape[0], 1)\n",
    "    return new_policy, value_state\n",
    "\n",
    "def print_policy(policy):\n",
    "    pol = (policy.reshape(441, 11).argmax(axis=1) - 5).reshape(21, 21)\n",
    "    print(\"    \", \" \".join(map(lambda x: \"%2d\" % x, range(0, 21))))\n",
    "    print(\"    ---------------------------------------------------------------\")\n",
    "    for row in range(20, -1, -1):\n",
    "        line = []\n",
    "        for col in range(0, 21):\n",
    "            line.append(pol[row][col])\n",
    "        print(\"%2d\" % row , \"|\", \" \".join(map(lambda x: \"%2d\" % x, line)))\n",
    "\n",
    "for i in range(10):\n",
    "    new_policy_argmax, value_state = policy_iteration(policy, value_state, r)\n",
    "    new_policy = np.zeros([r.num_states, len(r.actions)])\n",
    "    new_policy[range(len(policy)), new_policy_argmax.reshape(new_policy_argmax.shape[0],)] = 1\n",
    "    new_policy = new_policy.reshape([r.num_states, len(r.actions), 1])\n",
    "\n",
    "    print(\"policy (0, 0):\", r.actions[new_policy[0].argmax()])\n",
    "    \n",
    "    diff = np.abs(policy - new_policy).max(axis=1)\n",
    "    old_policy = policy\n",
    "    policy = new_policy\n",
    "    \n",
    "    if diff[diff != 0].shape[0] != 0:\n",
    "        pass\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#policy.reshape(16,4).argmax(axis=1).reshape(4, 4), value_state.reshape(4,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n",
      "    ---------------------------------------------------------------\n",
      "20 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "19 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "18 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "17 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "16 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "15 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "14 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "13 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "12 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "11 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "10 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 9 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 8 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 7 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 6 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 5 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 4 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 3 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 2 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 1 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 0 |  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "print_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.075869456"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.rewards[8][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "value_state = np.full(r.num_states, 0)\n",
    "z = np.zeros(r.num_actions)\n",
    "z[5] = 1\n",
    "policy = np.full([r.num_states, len(r.actions)], z).reshape(r.num_states, len(r.actions), 1)\n",
    "\n",
    "value_state = policy_eval(policy, value_state, r, 0.9, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3923.80620389, -3041.80619864, -2159.80619864, -1277.80620079,\n",
       "        -395.80619793,   486.19380225,  -395.80619793, -1277.80620079,\n",
       "       -2159.80619864, -3041.80619864, -3923.80620389])"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(env.rewards + env.probabilities * (discount_factor*value_state)).sum(axis=2)[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-407.17051596472623"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(old_value_state - value_state).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.abs(old_policy - new_policy).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4002.8286389, -3120.8286389, -2238.8286389, -1356.8286389,\n",
       "        -474.8286389,   407.1713611,  -474.8286389, -1356.8286389,\n",
       "       -2238.8286389, -3120.8286389, -4002.8286389])"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(env.rewards + env.probabilities * (0.9*value_state)).sum(axis=2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.956916099773243"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2627)/441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.4839052081845442e-05, 0.0015962957071031193),\n",
       " (0.00012676247877899428, 0.0068498411518757183),\n",
       " (0.00053253080401237938, 0.024165431923476623),\n",
       " (0.0016554978932164178, 0.062617957167813904),\n",
       " (0.0037013226056729779, 0.11554889527942772),\n",
       " (0.0060735954235940212, 0.15579585342919114),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rental_probabilities_cache[((0, 8), i, (0, 8))] for i in range(-5, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3931.08322533, -3049.0832177 , -2167.0832177 , -1285.08322342,\n",
       "        -403.08322068,   478.91677981,  -403.08322068, -1285.08322342,\n",
       "       -2167.0832177 , -3049.0832177 , -3931.08322533])"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(env.rewards + env.probabilities * (0.9*value_state)).sum(axis=2)[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478.9159346749629"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_state[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
