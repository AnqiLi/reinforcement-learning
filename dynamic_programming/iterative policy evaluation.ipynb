{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gridworld(object):\n",
    "    def __init__(self, discount_factor = 1.0):\n",
    "        self.states = range(16)\n",
    "        self.num_states = len(self.states)\n",
    "        self.actions = [\"up\", \"down\", \"right\", \"left\"]\n",
    "        self.value_state = np.full(self.num_states, 0)\n",
    "        self.discount_factor = discount_factor\n",
    "        \n",
    "        self.policy = np.full([self.num_states, len(self.actions), 1], 1/len(self.actions))\n",
    "        self.reward = -1#np.full([self.num_states, len(self.actions), self.num_states], -1)\n",
    "        self.probabilities = np.full([self.num_states, len(self.actions), self.num_states], 0)\n",
    "        \n",
    "        for from_state in self.states:\n",
    "            for action in self.actions:\n",
    "                action_index = self.actions.index(action)\n",
    "                for to_state in self.states:\n",
    "                    p = self.probability(from_state, action, to_state)\n",
    "                    self.probabilities[from_state][action_index][to_state] = p\n",
    "                    \n",
    "    \n",
    "    def probability(self, from_position, action, to_position):\n",
    "        num_rows, num_cols = self.num_states / 4, self.num_states / 4\n",
    "        from_x, from_y = from_position//num_rows, from_position%num_cols\n",
    "        to_x, to_y = to_position//num_rows, to_position%num_cols\n",
    "        \n",
    "        if abs(to_x - from_x) > 1: return 0\n",
    "        if abs(to_y - from_y) > 1: return 0\n",
    "        \n",
    "        if from_x == 0 and from_x == to_x and from_y == to_y and action == \"up\":\n",
    "            return 1\n",
    "        if from_x == num_rows-1 and from_x == to_x and from_y == to_y and action == \"down\":\n",
    "            return 1\n",
    "        if from_y == 0 and from_x == to_x and from_y == to_y and action == \"left\":\n",
    "            return 1\n",
    "        if from_y == num_cols-1 and from_x == to_x and from_y == to_y and action == \"right\":\n",
    "            return 1\n",
    "        \n",
    "        if from_x == to_x and from_y == to_y: return 0\n",
    "        \n",
    "        if from_x == to_x + 1 and from_y == to_y + 1: return 0\n",
    "        if from_x == to_x - 1 and from_y == to_y - 1: return 0\n",
    "        if from_x == to_x + 1 and from_y == to_y - 1: return 0\n",
    "        if from_x == to_x - 1 and from_y == to_y + 1: return 0\n",
    "        \n",
    "        if from_x + 1 == to_x and action != \"down\": return 0\n",
    "        if from_x - 1 == to_x and action != \"up\": return 0\n",
    "        if from_y + 1 == to_y and action != \"right\": return 0\n",
    "        if from_y - 1 == to_y and action != \"left\": return 0\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    def policy_eval(self):\n",
    "        new_v_action_state = (self.value_state*self.discount_factor + self.reward)*self.probabilities*self.policy\n",
    "        new_v = new_v_action_state.sum(axis=2).sum(axis=1)\n",
    "        new_v.put([0, -1], [0, 0])\n",
    "        return new_v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        , -13.98945772, -19.98437823, -21.98251832],\n",
       "       [-13.98945772, -17.98623815, -19.98448273, -19.98437823],\n",
       "       [-19.98437823, -19.98448273, -17.98623815, -13.98945772],\n",
       "       [-21.98251832, -19.98437823, -13.98945772,   0.        ]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = 0.001\n",
    "grid = Gridworld()\n",
    "\n",
    "while True:\n",
    "    delta = 0\n",
    "    v = grid.value_state\n",
    "    grid.value_state = grid.policy_eval()\n",
    "    delta = max(delta, (v - grid.value_state).max())\n",
    "    if delta < theta:\n",
    "        break\n",
    "        \n",
    "grid.value_state.reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
