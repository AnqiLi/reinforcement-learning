{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alvaro/.asdf/installs/python/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/alvaro/.asdf/installs/python/3.6.3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gym, random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Discrete(2), Box(4,), (-inf, inf))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space, env.observation_space, env.reward_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_state = lambda state: state.reshape(1, env.observation_space.shape[0])\n",
    "def take_step(action):\n",
    "    new_state, reward, done, info = env.step(action)\n",
    "    return reshape_state(new_state), reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_in = tf.keras.layers.Input(env.observation_space.shape, name=\"state_in\")\n",
    "\n",
    "x = tf.keras.layers.Dense(8, activation=\"relu\")(state_in)\n",
    "# x = tf.keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(env.action_space.n, activation=\"linear\")(x)\n",
    "\n",
    "policy = tf.keras.models.Model([state_in], x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.1)\n",
    "policy.compile(optimizer=optimizer, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_in = tf.keras.layers.Input(env.observation_space.shape, name=\"state_in\")\n",
    "\n",
    "x = tf.keras.layers.Dense(8, activation=\"relu\")(state_in)\n",
    "# x = tf.keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "value = tf.keras.models.Model([state_in], x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.1)\n",
    "value.compile(optimizer=optimizer, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_value(value, state, td_target):\n",
    "    value.optimizer.lr = 0.005\n",
    "    value.fit(state, td_target, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(policy, delta, state, action):\n",
    "    predictions = policy.predict(state)\n",
    "    \n",
    "    for row in range(len(action)):\n",
    "        predictions[row, action] = delta\n",
    "    \n",
    "    policy.optimizer.lr = 0.005\n",
    "    policy.fit(state, predictions, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_to_onehot(action):\n",
    "    zeros = np.zeros(env.action_space.n, dtype=np.float32)\n",
    "    zeros[action] = 1.\n",
    "    return zeros.reshape(1, env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_replay_to_numpy(value_samples):\n",
    "    states, td_targets = [] , []\n",
    "    for state, td_target in value_samples:\n",
    "        states.append(state)\n",
    "        td_targets.append(td_target)\n",
    "    \n",
    "    states = np.array(states).reshape(len(states), env.observation_space.shape[0])\n",
    "    td_targets = np.array(td_targets).reshape(len(td_targets), 1)\n",
    "    return states, td_targets\n",
    "\n",
    "def policy_replay_to_numpy(policy_samples):\n",
    "    deltas, states, actions = [] , [], []\n",
    "    for delta, state, action in policy_samples:\n",
    "        deltas.append(delta)\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "    \n",
    "    deltas = np.array(deltas).reshape(len(deltas), 1)\n",
    "    states = np.array(states).reshape(len(states), env.observation_space.shape[0])\n",
    "    actions = np.array(actions).reshape(len(actions), 1)\n",
    "    return deltas, states, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "value_replay = deque([], 5000)\n",
    "policy_replay = deque([], 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(gamma=0.9, render=False, replay_size=100):\n",
    "    # reset\n",
    "    I = 1\n",
    "    lr_value = lr_policy = 0.01\n",
    "    step = 0\n",
    "    initial_state = state = reshape_state(env.reset())\n",
    "\n",
    "    while True:\n",
    "        if render: env.render()\n",
    "            \n",
    "        # choose action\n",
    "        action_probs = policy.predict(state)[0]\n",
    "        e_x = np.exp(action_probs - np.max(action_probs))\n",
    "        softmax_probs = e_x / e_x.sum()\n",
    "        action = np.random.choice(range(env.action_space.n), p=softmax_probs)\n",
    "    \n",
    "        # take action\n",
    "        new_state, reward, done, _ = take_step(action)\n",
    "\n",
    "        # calculate td error\n",
    "        if done:\n",
    "            td_target = np.array([reward], dtype=np.float32)\n",
    "        else:\n",
    "            td_target = reward + gamma * value.predict([new_state])[0]\n",
    "            \n",
    "        delta = td_target - value.predict(state)[0]\n",
    "        \n",
    "        # update value weights\n",
    "        value_replay.append((state, td_target))\n",
    "        update_value(value, [state], [td_target])\n",
    "        \n",
    "        # update policy weights\n",
    "        policy_replay.append((delta, state, action))\n",
    "        update_policy(policy, delta, [state], [action])\n",
    "        \n",
    "        if done:\n",
    "            value_samples = random.sample(value_replay, min(len(value_replay), replay_size))\n",
    "            states, td_targets = value_replay_to_numpy(value_samples)\n",
    "            update_value(value, states, td_targets)\n",
    "            \n",
    "            policy_samples = random.sample(policy_replay, min(len(policy_replay), replay_size))\n",
    "            deltas, states, actions = policy_replay_to_numpy(policy_samples)\n",
    "            update_policy(policy, deltas, states, actions)\n",
    "            \n",
    "            break\n",
    "\n",
    "        # update algorithm vars\n",
    "        # gamma = gamma * gamma\n",
    "        state = new_state\n",
    "        step += 1\n",
    "        if step > 500:\n",
    "            break\n",
    "    \n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.0 499.00000000000006\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEDCAYAAAAm3zNHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4EhSepiYEiSuhgYkqQuBoYkqcv/B7Sm92nedqlVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116a30278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = [run(gamma=1, render=True, replay_size=100) for i in range(3)]\n",
    "print(np.mean(steps), np.percentile(steps, 10))\n",
    "plt.scatter(range(len(steps)), steps, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value.save_weights(\"weights/value-cartpole-3000-iterations.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
