{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alvaro/.asdf/installs/python/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/alvaro/.asdf/installs/python/3.6.3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gym, random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Discrete(2), Box(4,), (-inf, inf))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space, env.observation_space, env.reward_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_state = lambda state: state.reshape(1, env.observation_space.shape[0])\n",
    "def take_step(action):\n",
    "    new_state, reward, done, info = env.step(action)\n",
    "    return reshape_state(new_state), reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_in = tf.keras.layers.Input(env.observation_space.shape, name=\"state_in\")\n",
    "\n",
    "x = tf.keras.layers.Dense(8, activation=\"relu\")(state_in)\n",
    "# x = tf.keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(env.action_space.n, activation=\"linear\")(x)\n",
    "\n",
    "policy = tf.keras.models.Model([state_in], x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.1)\n",
    "policy.compile(optimizer=optimizer, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_in = tf.keras.layers.Input(env.observation_space.shape, name=\"state_in\")\n",
    "\n",
    "x = tf.keras.layers.Dense(8, activation=\"relu\")(state_in)\n",
    "# x = tf.keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "value = tf.keras.models.Model([state_in], x)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.1)\n",
    "value.compile(optimizer=optimizer, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_value(value, state, td_target):\n",
    "    value.optimizer.lr = 0.01\n",
    "    value.fit(state, td_target, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(policy, delta, state, action):\n",
    "    predictions = policy.predict(state)\n",
    "    \n",
    "    for row in range(len(action)):\n",
    "        predictions[row, action] = delta\n",
    "    \n",
    "    policy.optimizer.lr = 0.01\n",
    "    policy.fit(state, predictions, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_to_onehot(action):\n",
    "    zeros = np.zeros(env.action_space.n, dtype=np.float32)\n",
    "    zeros[action] = 1.\n",
    "    return zeros.reshape(1, env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_replay_to_numpy(value_samples):\n",
    "    states, td_targets = [] , []\n",
    "    for state, td_target in value_samples:\n",
    "        states.append(state)\n",
    "        td_targets.append(td_target)\n",
    "    \n",
    "    states = np.array(states).reshape(len(states), env.observation_space.shape[0])\n",
    "    td_targets = np.array(td_targets).reshape(len(td_targets), 1)\n",
    "    return states, td_targets\n",
    "\n",
    "def policy_replay_to_numpy(policy_samples):\n",
    "    deltas, states, actions = [] , [], []\n",
    "    for delta, state, action in policy_samples:\n",
    "        deltas.append(delta)\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "    \n",
    "    deltas = np.array(deltas).reshape(len(deltas), 1)\n",
    "    states = np.array(states).reshape(len(states), env.observation_space.shape[0])\n",
    "    actions = np.array(actions).reshape(len(actions), 1)\n",
    "    return deltas, states, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "value_replay = deque([], 5000)\n",
    "policy_replay = deque([], 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(gamma=0.9, render=False, replay_size=100):\n",
    "    # reset\n",
    "    I = 1\n",
    "    lr_value = lr_policy = 0.01\n",
    "    step = 0\n",
    "    initial_state = state = reshape_state(env.reset())\n",
    "\n",
    "    while True:\n",
    "        if render: env.render()\n",
    "            \n",
    "        # choose action\n",
    "        action_probs = policy.predict(state)[0]\n",
    "        e_x = np.exp(action_probs - np.max(action_probs))\n",
    "        softmax_probs = e_x / e_x.sum()\n",
    "        action = np.random.choice(range(env.action_space.n), p=softmax_probs)\n",
    "    \n",
    "        # take action\n",
    "        new_state, reward, done, _ = take_step(action)\n",
    "\n",
    "        # calculate td error\n",
    "        if done:\n",
    "            td_target = np.array([reward], dtype=np.float32)\n",
    "        else:\n",
    "            td_target = reward + gamma * value.predict([new_state])[0]\n",
    "            \n",
    "        delta = td_target - value.predict(state)[0]\n",
    "        \n",
    "        # update value weights\n",
    "        value_replay.append((state, td_target))\n",
    "        update_value(value, [state], [td_target])\n",
    "        \n",
    "        # update policy weights\n",
    "        policy_replay.append((delta, state, action))\n",
    "        update_policy(policy, delta, [state], [action])\n",
    "        \n",
    "        if done:\n",
    "            value_samples = random.sample(value_replay, min(len(value_replay), replay_size))\n",
    "            states, td_targets = value_replay_to_numpy(value_samples)\n",
    "            update_value(value, states, td_targets)\n",
    "            \n",
    "            policy_samples = random.sample(policy_replay, min(len(policy_replay), replay_size))\n",
    "            deltas, states, actions = policy_replay_to_numpy(policy_samples)\n",
    "            update_policy(policy, deltas, states, actions)\n",
    "            \n",
    "            break\n",
    "\n",
    "        # update algorithm vars\n",
    "        # gamma = gamma * gamma\n",
    "        state = new_state\n",
    "        step += 1\n",
    "        if step > 500:\n",
    "            break\n",
    "    \n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.23 8.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d4b4668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = [run(gamma=1, render=False, replay_size=100) for i in range(100)]\n",
    "print(np.mean(steps), np.percentile(steps, 10))\n",
    "plt.scatter(range(len(steps)), steps, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
